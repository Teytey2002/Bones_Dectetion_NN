First test with 4 couches de conv
----- âœ… Evaluation terminÃ©e -----
Classification Accuracy: 48.19%
SmoothL1 Loss Moyenne par point: 0.018304

conv5
----- âœ… Evaluation terminÃ©e -----
Classification Accuracy: 57.83%
SmoothL1 Loss Moyenne par point: 0.021670

conv6 
----- âœ… Evaluation terminÃ©e -----
Classification Accuracy: 50.60%
SmoothL1 Loss Moyenne par point: 0.016114

conv7 
----- âœ… Evaluation terminÃ©e -----
Classification Accuracy: 61.45%
SmoothL1 Loss Moyenne par point: 0.016968


Quand j'ai voulu faire un train avec conv8 Ã§a a crash j'ai atteint la limite du pooling. 
Notion importante Ã  prendre en compte car au final je me retrouve avec des jeux d'image de 1 pixels Ã  la fin et il y a plus aucune information
dedans donc on fait du pooling pour avoir max 7 pixels Ã  la fin.

Du coup ici nouveau model profond avec 10 couches de conv et du pooling toutes les 2 couches 

Au dÃ©but les rÃ©sulatts sont nuls : 
Epoch [73], Train Loss: 1.7726, Valid Loss: 1.7856,           Train Acc: 24.00%, Valid Acc: 23.70%
â¸ï¸ Pas d'amÃ©lioration depuis 20 epoch(s)
ğŸ›‘ Early stopping dÃ©clenchÃ©

on voit bien que le model n'apprend rien. J'ajoute donc une normalisation autour de 0 donc [-1,1]
-> Aucune diff j'ai changÃ© le learning rate de 0,001 Ã  0,0003

pour conv10_normalized avec LR = 0,0003 et sans scheduler 
Epoch [28], Train Loss: 0.2249, Valid Loss: 2.7124,           Train Acc: 93.46%, Valid Acc: 58.96%
â¸ï¸ Pas d'amÃ©lioration depuis 20 epoch(s)
ğŸ›‘ Early stopping dÃ©clenchÃ©

----- âœ… Evaluation terminÃ©e -----
Classification Accuracy: 57.83%
SmoothL1 Loss Moyenne par point: 0.021670


Ajout d'un scheduler et en gardant la normalisation

Avec un LR de 0.0003 et scheduler factor 0.8 -> conv10_normalized_schdule
Epoch [41], Train Loss: 0.3347, Valid Loss: 2.3839,           Train Acc: 88.08%, Valid Acc: 69.36%
â¸ï¸ Pas d'amÃ©lioration depuis 20 epoch(s)
ğŸ›‘ Early stopping dÃ©clenchÃ©

----- âœ… Evaluation terminÃ©e -----
Classification Accuracy: 51.81%
SmoothL1 Loss Moyenne par point: 0.018836

Conclusion on garde toujours le LR de 0,0003 pour point de dÃ©part 

ATTENTION IMPORTANT 
il faut bien dire de le rapport que ici on fait une loss total qui somme la loss de la detection et celle de la classification 
donc Ã§a veut dire que ce qui est eralyr stop et scheduler se base sur le total. On peut donc s'ameliorer sur le clasification et 
diminuÃ© sur la detection se qui fera stganer le total et entrainemra une fin du train alors que le model apprend encore 

On peut aussi dire qu'on a pas de data augmentation et que Ã§a peut epxliquer qu'on est des moins bon resulats pour la classfication que quand on a le model de classification seul avec la data augmtentation



Prochain test, pas de early stop. Scheduler avec factor = 0.9 et une patiente de 10    --conv10_normlized_1000epochs
ğŸ“‰ Learning Rate actuel: 0.000002
Epoch [361], Train Loss: 0.0144, Valid Loss: 11.5874,           Train Acc: 99.61%, Valid Acc: 65.90%
â¸ï¸ Pas d'amÃ©lioration depuis 321 epoch(s)

On peut voir les limites du model car il appris l'entrainenment par coeur mais la validation n'est pas encore parfaite. 
bloquÃ© dans un mimimum local 


On va tester un droptout de 0.7 au lieu de 0.5 --> conv10_normalized_schdule_0.7dp
ğŸ“‰ Learning Rate actuel: 0.000219
Epoch [65], Train Loss: 1.7772, Valid Loss: 1.7847,           Train Acc: 24.00%, Valid Acc: 23.70%
â¸ï¸ Pas d'amÃ©lioration depuis 25 epoch(s)
ğŸ›‘ Early stopping dÃ©clenchÃ©


test dropout 0.6 --> conv10_normalized_schdule_0.6dp
ğŸ“‰ Learning Rate actuel: 0.000243
Epoch [61], Train Loss: 0.1293, Valid Loss: 3.5536,           Train Acc: 94.84%, Valid Acc: 68.21%
â¸ï¸ Pas d'amÃ©lioration depuis 25 epoch(s)
ğŸ›‘ Early stopping dÃ©clenchÃ©